{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit from news classifier from here: https://www.kaggle.com/code/dimitriosroussis/news-articles-classification-tf-idf-voting/notebook\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "np.random.seed(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'#pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!#pip uninstall matplotlib\n",
    "#!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset read in \n",
    "with open('dataset/evidence.json') as json_file:\n",
    "    evidence = json.load(json_file)\n",
    "\n",
    "with open('dataset/dev-claims.json') as json_file:\n",
    "    dev_claim = json.load(json_file)\n",
    "\n",
    "with open('dataset/train-claims.json') as json_file:\n",
    "    train = json.load(json_file)\n",
    "\n",
    "with open('dataset/test-claims-unlabelled.json') as json_file:\n",
    "    test = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208827\n",
      "3121\n",
      "463\n",
      "0.0025818417358315126\n",
      "0.0003830159319737233\n",
      "0.045177827619352774\n",
      "0.3045356371490281\n",
      "0.00011664200088184661\n"
     ]
    }
   ],
   "source": [
    "print(len(evidence.keys()))\n",
    "evi_used_train = []\n",
    "evi_used_dev = []\n",
    "for key in train.keys():\n",
    "    evi_used_train += train[key]['evidences']\n",
    "evi_used_train = list(set(evi_used_train))\n",
    "\n",
    "for key in dev_claim.keys():\n",
    "    evi_used_dev += dev_claim[key]['evidences']\n",
    "evi_used_dev = list(set(evi_used_dev))\n",
    "\n",
    "print(len(evi_used_train))\n",
    "print(len(evi_used_dev))\n",
    "print(len(evi_used_train)/len(evidence.keys()))\n",
    "print(len(evi_used_dev)/len(evidence.keys()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "common = len(list(set(evi_used_train).intersection(evi_used_dev)))\n",
    "print(common/len(evi_used_train))\n",
    "print(common/len(evi_used_dev))\n",
    "print(common/len(evidence.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_da = []\n",
    "for key in test.keys():\n",
    "    test_da.append(test[key]['claim_text'])\n",
    "#print(len(test_da))\n",
    "dataset = {'text':test_da}\n",
    "data_test = pd.DataFrame.from_dict(dataset)\n",
    "X_test = data_test['text'].values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not only is there no scientific evidence that ...</td>\n",
       "      <td>DISPUTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El Niño drove record highs in global temperatu...</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 1946, PDO switched to a cool phase.</td>\n",
       "      <td>SUPPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weather Channel co-founder John Coleman provid...</td>\n",
       "      <td>DISPUTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"January 2008 capped a 12 month period of glob...</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text            label\n",
       "0  Not only is there no scientific evidence that ...         DISPUTED\n",
       "1  El Niño drove record highs in global temperatu...          REFUTES\n",
       "2             In 1946, PDO switched to a cool phase.         SUPPORTS\n",
       "3  Weather Channel co-founder John Coleman provid...         DISPUTED\n",
       "4  \"January 2008 capped a 12 month period of glob...  NOT_ENOUGH_INFO"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre processing, without evicence\n",
    "label = []\n",
    "claim_text = []\n",
    "for key in train.keys():\n",
    "    label.append(train[key]['claim_label'])\n",
    "    claim_text.append(train[key]['claim_text'])\n",
    "\n",
    "dataset = {'text':claim_text, 'label':label}\n",
    "data = pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not only is there no scientific evidence that ...</td>\n",
       "      <td>DISPUTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El Niño drove record highs in global temperatu...</td>\n",
       "      <td>REFUTES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In 1946, PDO switched to a cool phase. evidenc...</td>\n",
       "      <td>SUPPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Weather Channel co-founder John Coleman provid...</td>\n",
       "      <td>DISPUTED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"January 2008 capped a 12 month period of glob...</td>\n",
       "      <td>NOT_ENOUGH_INFO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text            label\n",
       "0  Not only is there no scientific evidence that ...         DISPUTED\n",
       "1  El Niño drove record highs in global temperatu...          REFUTES\n",
       "2  In 1946, PDO switched to a cool phase. evidenc...         SUPPORTS\n",
       "3  Weather Channel co-founder John Coleman provid...         DISPUTED\n",
       "4  \"January 2008 capped a 12 month period of glob...  NOT_ENOUGH_INFO"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre processing, with evicence and only evidence id\n",
    "label = []\n",
    "text = []\n",
    "for key in train.keys():\n",
    "    local = train[key][\"claim_text\"] + ' '\n",
    "    evi = [i for i in (train[key]['evidences'])] \n",
    "    local += ' '.join(evi)\n",
    "    label.append(train[key]['claim_label'])\n",
    "    text.append(local)\n",
    "\n",
    "dataset = {'text':text, 'label':label}\n",
    "data_evid = pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "data_evid.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not only is there no scientific evidence that CO2 is a pollutant, higher CO2 concentrations actually help ecosystems support more plant and animal life. At very high concentrations (100 times atmospheric concentration, or greater), carbon dioxide can be toxic to animal life, so raising the concentration to 10,000 ppm (1%) or higher for several hours will eliminate pests such as whiteflies and spider mites in a greenhouse. Plants can grow as much as 50 percent faster in concentrations of 1,000 ppm CO 2 when compared with ambient conditions, though this assumes no change in climate and no limitation on other nutrients. Higher carbon dioxide concentrations will favourably affect plant growth and demand for water.\n"
     ]
    }
   ],
   "source": [
    "#pre processing, with evicence text\n",
    "label = []\n",
    "text = []\n",
    "for key in train.keys():\n",
    "    local = train[key][\"claim_text\"] + ' '\n",
    "    evi = [i for i in (train[key]['evidences'])] \n",
    "    evi_text = []\n",
    "    for id in evi:\n",
    "        evi_text.append(evidence[id])\n",
    "    local += ' '.join(evi_text)\n",
    "    label.append(train[key]['claim_label'])\n",
    "    text.append(local)\n",
    "\n",
    "\n",
    "\n",
    "dataset = {'text':text, 'label':label}\n",
    "data_evte = pd.DataFrame.from_dict(dataset)\n",
    "\n",
    "data_evte.head()\n",
    "print(data_evte.text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "DISPUTED           0.100977\n",
      "NOT_ENOUGH_INFO    0.314332\n",
      "REFUTES            0.162052\n",
      "SUPPORTS           0.422638\n",
      "Name: text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#checking wether 0R is a good choice(Actually not bad)\n",
    "rel_freq = data.groupby('label').text.count() / len(data)\n",
    "print(rel_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, metrics):\n",
    "    metrics[0] += accuracy_score(y_true, y_pred)\n",
    "    metrics[1] += precision_score(y_true, y_pred, average='macro')\n",
    "    metrics[2] += recall_score(y_true, y_pred, average='macro')\n",
    "    metrics[3] += f1_score(y_true, y_pred, average='macro')\n",
    "    return metrics\n",
    "\n",
    "def evaluate_classifier(clf, kfold, X, y, vectorizer):\n",
    "    metrics = np.zeros(4)\n",
    "    start = timer()\n",
    "    for train, cv in kfold.split(X, y):\n",
    "        X_train, X_cv = X[train], X[cv]\n",
    "        y_train, y_cv = y[train], y[cv]\n",
    "        X_train_gen = [x for x in X_train]\n",
    "        #vectorizer.fit(X_train_gen)\n",
    "        X_train_vec = vectorizer.transform(X_train_gen)\n",
    "        clf.fit(X_train_vec, y_train)\n",
    "        X_cv_gen = [x for x in X_cv]\n",
    "        X_cv_vec = vectorizer.transform(X_cv_gen)\n",
    "        y_pred = clf.predict(X_cv_vec)\n",
    "        metrics = get_metrics(y_cv, y_pred, metrics)\n",
    "    dt = timer() - start\n",
    "    metrics = metrics * 100 / 5\n",
    "    print('Evaluation of classifier finished in {:.2f} s \\n'\n",
    "          'Average accuracy: {:.2f} % \\n'\n",
    "          'Average precision: {:.2f} % \\n'\n",
    "          'Average recall: {:.2f} % \\n'\n",
    "          'Average F-Measure: {:.2f} % \\n'\n",
    "          .format(dt, metrics[0], metrics[1],\n",
    "                  metrics[2], metrics[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=56)\n",
    "\n",
    "#stop_words = list(ENGLISH_STOP_WORDS)\n",
    "stop_words = stopwords.words('english')\n",
    "#print(stopwords)\n",
    "tfidf = TfidfVectorizer(stop_words = stop_words)\n",
    "#stop_words = stop_words\n",
    "trainner = []\n",
    "\n",
    "for i in evidence.keys():\n",
    "    trainner.append(evidence[i])\n",
    "for key in train.keys():\n",
    "    trainner.append(train[key]['claim_text'])\n",
    "for key in test.keys():\n",
    "    trainner.append(test[key]['claim_text'])\n",
    "#c_t = [x for x in text] \n",
    "#trainner += c_t\n",
    "tfidf.fit(raw_documents = trainner)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text'].values\n",
    "y = data['label'].values\n",
    "\n",
    "\n",
    "X_train_cv, X_test, y_train_cv, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                          random_state=56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of classifier finished in 0.31 s \n",
      "Average accuracy: 45.01 % \n",
      "Average precision: 38.26 % \n",
      "Average recall: 33.78 % \n",
      "Average F-Measure: 33.32 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = LinearSVC(tol=1e-05, max_iter=1500)\n",
    "evaluate_classifier(svm, kf, X_train_cv, y_train_cv, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of classifier finished in 2.65 s \n",
      "Average accuracy: 45.62 % \n",
      "Average precision: 35.31 % \n",
      "Average recall: 33.01 % \n",
      "Average F-Measure: 31.78 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeClassifier(alpha=0.8, tol=1e-05)\n",
    "evaluate_classifier(ridge, kf, X_train_cv, y_train_cv, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a1360\\anaconda3\\envs\\sklearn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\a1360\\anaconda3\\envs\\sklearn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of classifier finished in 0.28 s \n",
      "Average accuracy: 42.87 % \n",
      "Average precision: 28.91 % \n",
      "Average recall: 30.49 % \n",
      "Average F-Measure: 28.02 % \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\a1360\\anaconda3\\envs\\sklearn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "n_neight = 21\n",
    "knn = KNeighborsClassifier(n_neighbors = n_neight, n_jobs=-1, weights = 'distance')\n",
    "evaluate_classifier(knn, kf, X_train_cv, y_train_cv, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "DISPUTED\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "REFUTES\n",
      "NOT_ENOUGH_INFO\n",
      "REFUTES\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "DISPUTED\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "DISPUTED\n",
      "SUPPORTS\n",
      "DISPUTED\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "DISPUTED\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "REFUTES\n",
      "NOT_ENOUGH_INFO\n",
      "NOT_ENOUGH_INFO\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "DISPUTED\n",
      "SUPPORTS\n",
      "DISPUTED\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "REFUTES\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "DISPUTED\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "DISPUTED\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "DISPUTED\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "REFUTES\n",
      "SUPPORTS\n",
      "NOT_ENOUGH_INFO\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n",
      "SUPPORTS\n"
     ]
    }
   ],
   "source": [
    "# my knn\n",
    "train_e = tfidf.transform(X)\n",
    "train_id = list(train.keys())\n",
    "k = 7\n",
    "res = {}\n",
    "\n",
    "for key in test.keys():\n",
    "    e_test = tfidf.transform([test[key]['claim_text']])\n",
    "    distance = {}\n",
    "    simila = cosine_similarity(e_test, train_e)[0]\n",
    "    for i in range(len(simila)):\n",
    "        distance[train_id[i]]= simila[i]\n",
    "\n",
    "    sim = [(k, v) for k, v in sorted(distance.items(), key=lambda item: item[1],reverse=True)][:k]\n",
    "    sel = [key for key,v in sim]\n",
    "    temp = {}\n",
    "    for id in sel:\n",
    "        label = train[id]['claim_label']\n",
    "        if label in temp.keys():\n",
    "            temp[label] += 1\n",
    "        else:\n",
    "            temp[label] = 1\n",
    "    \n",
    "    best = [label for label in sorted(temp.items(), key=lambda item: item[1],reverse=True)][0][0]\n",
    "    #print(best)\n",
    "    res[key] = {'claim_label':best}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'claim-2967': {'claim_label': 'SUPPORTS'}, 'claim-979': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-1609': {'claim_label': 'SUPPORTS'}, 'claim-1020': {'claim_label': 'SUPPORTS'}, 'claim-2599': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2110': {'claim_label': 'SUPPORTS'}, 'claim-1135': {'claim_label': 'SUPPORTS'}, 'claim-712': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-1307': {'claim_label': 'SUPPORTS'}, 'claim-148': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-903': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2942': {'claim_label': 'SUPPORTS'}, 'claim-1001': {'claim_label': 'REFUTES'}, 'claim-1034': {'claim_label': 'SUPPORTS'}, 'claim-1009': {'claim_label': 'REFUTES'}, 'claim-770': {'claim_label': 'SUPPORTS'}, 'claim-3074': {'claim_label': 'SUPPORTS'}, 'claim-1761': {'claim_label': 'SUPPORTS'}, 'claim-1475': {'claim_label': 'SUPPORTS'}, 'claim-477': {'claim_label': 'SUPPORTS'}, 'claim-1378': {'claim_label': 'DISPUTED'}, 'claim-503': {'claim_label': 'SUPPORTS'}, 'claim-2751': {'claim_label': 'SUPPORTS'}, 'claim-2575': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-30': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2994': {'claim_label': 'SUPPORTS'}, 'claim-55': {'claim_label': 'REFUTES'}, 'claim-1271': {'claim_label': 'REFUTES'}, 'claim-2248': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-532': {'claim_label': 'REFUTES'}, 'claim-556': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-1173': {'claim_label': 'SUPPORTS'}, 'claim-539': {'claim_label': 'DISPUTED'}, 'claim-893': {'claim_label': 'SUPPORTS'}, 'claim-2857': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-109': {'claim_label': 'SUPPORTS'}, 'claim-2476': {'claim_label': 'SUPPORTS'}, 'claim-3038': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-3127': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-474': {'claim_label': 'SUPPORTS'}, 'claim-2464': {'claim_label': 'DISPUTED'}, 'claim-2427': {'claim_label': 'SUPPORTS'}, 'claim-2167': {'claim_label': 'DISPUTED'}, 'claim-812': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2590': {'claim_label': 'SUPPORTS'}, 'claim-404': {'claim_label': 'REFUTES'}, 'claim-2977': {'claim_label': 'REFUTES'}, 'claim-2673': {'claim_label': 'SUPPORTS'}, 'claim-2509': {'claim_label': 'SUPPORTS'}, 'claim-138': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-952': {'claim_label': 'DISPUTED'}, 'claim-1691': {'claim_label': 'SUPPORTS'}, 'claim-1741': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-1202': {'claim_label': 'SUPPORTS'}, 'claim-1028': {'claim_label': 'SUPPORTS'}, 'claim-28': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-275': {'claim_label': 'REFUTES'}, 'claim-350': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2204': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-1604': {'claim_label': 'REFUTES'}, 'claim-3119': {'claim_label': 'SUPPORTS'}, 'claim-2150': {'claim_label': 'DISPUTED'}, 'claim-21': {'claim_label': 'SUPPORTS'}, 'claim-2013': {'claim_label': 'DISPUTED'}, 'claim-467': {'claim_label': 'SUPPORTS'}, 'claim-2754': {'claim_label': 'SUPPORTS'}, 'claim-2797': {'claim_label': 'SUPPORTS'}, 'claim-1771': {'claim_label': 'REFUTES'}, 'claim-1908': {'claim_label': 'SUPPORTS'}, 'claim-2000': {'claim_label': 'SUPPORTS'}, 'claim-2084': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-1237': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-400': {'claim_label': 'SUPPORTS'}, 'claim-1508': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-520': {'claim_label': 'SUPPORTS'}, 'claim-3064': {'claim_label': 'SUPPORTS'}, 'claim-1588': {'claim_label': 'SUPPORTS'}, 'claim-1488': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2733': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-809': {'claim_label': 'SUPPORTS'}, 'claim-763': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-454': {'claim_label': 'REFUTES'}, 'claim-1853': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2838': {'claim_label': 'SUPPORTS'}, 'claim-2028': {'claim_label': 'SUPPORTS'}, 'claim-2434': {'claim_label': 'REFUTES'}, 'claim-298': {'claim_label': 'SUPPORTS'}, 'claim-338': {'claim_label': 'REFUTES'}, 'claim-1672': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2840': {'claim_label': 'SUPPORTS'}, 'claim-1425': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-1985': {'claim_label': 'SUPPORTS'}, 'claim-1156': {'claim_label': 'REFUTES'}, 'claim-2870': {'claim_label': 'SUPPORTS'}, 'claim-2898': {'claim_label': 'SUPPORTS'}, 'claim-2329': {'claim_label': 'SUPPORTS'}, 'claim-1998': {'claim_label': 'SUPPORTS'}, 'claim-2209': {'claim_label': 'SUPPORTS'}, 'claim-1582': {'claim_label': 'SUPPORTS'}, 'claim-3072': {'claim_label': 'REFUTES'}, 'claim-381': {'claim_label': 'SUPPORTS'}, 'claim-398': {'claim_label': 'SUPPORTS'}, 'claim-1560': {'claim_label': 'REFUTES'}, 'claim-2246': {'claim_label': 'SUPPORTS'}, 'claim-2774': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-972': {'claim_label': 'SUPPORTS'}, 'claim-1531': {'claim_label': 'SUPPORTS'}, 'claim-2592': {'claim_label': 'REFUTES'}, 'claim-2468': {'claim_label': 'DISPUTED'}, 'claim-463': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-616': {'claim_label': 'SUPPORTS'}, 'claim-1240': {'claim_label': 'SUPPORTS'}, 'claim-2951': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-1977': {'claim_label': 'SUPPORTS'}, 'claim-942': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2755': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-1230': {'claim_label': 'SUPPORTS'}, 'claim-3123': {'claim_label': 'SUPPORTS'}, 'claim-1684': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-839': {'claim_label': 'SUPPORTS'}, 'claim-2423': {'claim_label': 'SUPPORTS'}, 'claim-1243': {'claim_label': 'DISPUTED'}, 'claim-494': {'claim_label': 'SUPPORTS'}, 'claim-1458': {'claim_label': 'SUPPORTS'}, 'claim-461': {'claim_label': 'REFUTES'}, 'claim-1304': {'claim_label': 'DISPUTED'}, 'claim-2564': {'claim_label': 'SUPPORTS'}, 'claim-2121': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2631': {'claim_label': 'SUPPORTS'}, 'claim-1141': {'claim_label': 'SUPPORTS'}, 'claim-2398': {'claim_label': 'SUPPORTS'}, 'claim-1048': {'claim_label': 'SUPPORTS'}, 'claim-2783': {'claim_label': 'REFUTES'}, 'claim-1003': {'claim_label': 'SUPPORTS'}, 'claim-1872': {'claim_label': 'SUPPORTS'}, 'claim-1842': {'claim_label': 'SUPPORTS'}, 'claim-2411': {'claim_label': 'REFUTES'}, 'claim-2428': {'claim_label': 'SUPPORTS'}, 'claim-1198': {'claim_label': 'SUPPORTS'}, 'claim-678': {'claim_label': 'SUPPORTS'}, 'claim-2105': {'claim_label': 'SUPPORTS'}, 'claim-648': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-822': {'claim_label': 'SUPPORTS'}, 'claim-2561': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-2219': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-1343': {'claim_label': 'SUPPORTS'}, 'claim-1351': {'claim_label': 'REFUTES'}, 'claim-2347': {'claim_label': 'SUPPORTS'}, 'claim-293': {'claim_label': 'NOT_ENOUGH_INFO'}, 'claim-910': {'claim_label': 'SUPPORTS'}, 'claim-2815': {'claim_label': 'SUPPORTS'}, 'claim-1652': {'claim_label': 'SUPPORTS'}, 'claim-1212': {'claim_label': 'SUPPORTS'}}\n"
     ]
    }
   ],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost = VotingClassifier(estimators=[\n",
    "                        ('svc', svm), ('ridge', ridge), ('knn', knn)],\n",
    "                        voting='hard', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of voting classifier on the test set finished in 2.37 s . \n",
      "Average accuracy: 48.37 % \n",
      "Average precision: 40.84 % \n",
      "Average recall: 37.50 % \n",
      "Average F-Measure: 36.86 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "metrics = np.zeros(4)\n",
    "X_train_gen = [x for x in X_train_cv]\n",
    "tfidf.fit(X_train_gen)\n",
    "X_train_vec = tfidf.transform(X_train_gen)\n",
    "boost.fit(X_train_vec, y_train_cv)\n",
    "X_test_gen = [x for x in X_test]\n",
    "X_test_vec = tfidf.transform(X_test_gen)\n",
    "y_pred = boost.predict(X_test_vec)\n",
    "metrics = get_metrics(y_test, y_pred, metrics)\n",
    "dt = timer() - start\n",
    "metrics = metrics * 100\n",
    "print('Evaluation of voting classifier on the test set finished in {:.2f} s . \\n'\n",
    "      'Average accuracy: {:.2f} % \\n'\n",
    "      'Average precision: {:.2f} % \\n'\n",
    "      'Average recall: {:.2f} % \\n'\n",
    "      'Average F-Measure: {:.2f} % \\n'\n",
    "      .format(dt, metrics[0], metrics[1],\n",
    "              metrics[2], metrics[3]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'NOT_ENOUGH_INFO', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'NOT_ENOUGH_INFO', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'NOT_ENOUGH_INFO', 'NOT_ENOUGH_INFO', 'SUPPORTS', 'SUPPORTS', 'REFUTES', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'REFUTES', 'REFUTES', 'SUPPORTS', 'SUPPORTS', 'NOT_ENOUGH_INFO', 'REFUTES', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'DISPUTED', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'NOT_ENOUGH_INFO', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'NOT_ENOUGH_INFO', 'SUPPORTS', 'SUPPORTS', 'REFUTES', 'SUPPORTS', 'NOT_ENOUGH_INFO', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'NOT_ENOUGH_INFO', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'REFUTES', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'REFUTES', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'REFUTES', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'REFUTES', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'REFUTES', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'REFUTES', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'REFUTES', 'NOT_ENOUGH_INFO', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'NOT_ENOUGH_INFO', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'SUPPORTS', 'NOT_ENOUGH_INFO', 'SUPPORTS', 'SUPPORTS']\n"
     ]
    }
   ],
   "source": [
    "#prediction\n",
    "\n",
    "X_test = [x for x in X_test]\n",
    "#print(len(X_test))\n",
    "X_test_vec = tfidf.transform(X_test)\n",
    "y_pred = boost.predict(X_test_vec).tolist()\n",
    "#print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = np.load('test.npy').tolist()\n",
    "\n",
    "\n",
    "with open('evi_f.json') as json_file:\n",
    "    format = json.load(json_file)\n",
    "\n",
    "#with open('sample.json') as json_file:\n",
    "    #label = json.load(json_file)\n",
    "\n",
    "\n",
    "counter = 0\n",
    "for key in format.keys():\n",
    "    format[key]['claim_label'] = res[key]['claim_label']\n",
    "    counter +=1\n",
    "\n",
    "file_path = 'eval_ff.json'\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(format, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
